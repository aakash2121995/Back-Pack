{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Background Blurring.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJWZ2b4ERqbB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "e2243e15-f121-4895-fb73-bccd4b13d47b"
      },
      "source": [
        "! git clone https://github.com/zllrunning/face-parsing.PyTorch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'face-parsing.PyTorch'...\n",
            "remote: Enumerating objects: 92, done.\u001b[K\n",
            "remote: Total 92 (delta 0), reused 0 (delta 0), pack-reused 92\u001b[K\n",
            "Unpacking objects: 100% (92/92), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHdDxZsdSM2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir -p face-parsing.PyTorch/res/cp "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHyc6BwWRth2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "3c36c86a-1111-42c9-e5c9-b797cb55ad78"
      },
      "source": [
        "!wget --output-document=79999_iter.pth 'https://drive.google.com/u/0/uc?id=154JgKpzCPW82qINcVieuPH3fZ2e0P812&export=download'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-13 12:24:48--  https://drive.google.com/u/0/uc?id=154JgKpzCPW82qINcVieuPH3fZ2e0P812&export=download\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.129.102, 74.125.129.139, 74.125.129.101, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.129.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-10-1s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/bjt2l1p0l7nhro1dpasn50mgm81j9hle/1594643025000/11347955420423960128/*/154JgKpzCPW82qINcVieuPH3fZ2e0P812?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-07-13 12:24:50--  https://doc-10-1s-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/bjt2l1p0l7nhro1dpasn50mgm81j9hle/1594643025000/11347955420423960128/*/154JgKpzCPW82qINcVieuPH3fZ2e0P812?e=download\n",
            "Resolving doc-10-1s-docs.googleusercontent.com (doc-10-1s-docs.googleusercontent.com)... 173.194.197.132, 2607:f8b0:4001:c1b::84\n",
            "Connecting to doc-10-1s-docs.googleusercontent.com (doc-10-1s-docs.googleusercontent.com)|173.194.197.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/octet-stream]\n",
            "Saving to: ‘79999_iter.pth’\n",
            "\n",
            "79999_iter.pth          [  <=>               ]  50.82M   160MB/s    in 0.3s    \n",
            "\n",
            "2020-07-13 12:24:51 (160 MB/s) - ‘79999_iter.pth’ saved [53289463]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ng5ShHN3SzrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp 79999_iter.pth face-parsing.PyTorch/res/cp "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3iwh0ipTIkc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/python\n",
        "# -*- encoding: utf-8 -*-\n",
        "import sys\n",
        "sys.path.insert(1,'face-parsing.PyTorch')\n",
        "from logger import setup_logger\n",
        "from model import BiSeNet\n",
        "\n",
        "import torch\n",
        "\n",
        "import os\n",
        "import os.path as osp\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "import cv2"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqzVuuYMXUOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def evaluate(input_video,respth='./res/test_res', cp='model_final_diss.pth',kernel_size=(31,31),blur=True,background = None,fps=30):\n",
        "  '''\n",
        "  input_video : Path for the input video\n",
        "  cp: Weight file\n",
        "  kernel_size: Size of the Gaussian kernel for blurring\n",
        "  blur: Set to True to perform blurring else the function performs background replacement\n",
        "  background: Background to be used for replacement in the video, irrelevant if blur is set to True\n",
        "  fps: Output frames per second\n",
        "  '''\n",
        "\n",
        "  if not os.path.exists(respth):\n",
        "      os.makedirs(respth)\n",
        "\n",
        "  n_classes = 19\n",
        "\n",
        "  # loading network\n",
        "  net = BiSeNet(n_classes=n_classes)\n",
        "  net.cuda()\n",
        "  save_pth = osp.join('face-parsing.PyTorch/res/cp', cp)\n",
        "  net.load_state_dict(torch.load(save_pth))\n",
        "  net.eval()\n",
        "\n",
        "  # normailsation constants\n",
        "  to_tensor = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "  ])\n",
        "\n",
        "  # setting file names and reading background files\n",
        "  if blur:\n",
        "    output_file_name = 'blur_background_video.avi'\n",
        "  else:\n",
        "    output_file_name = 'change_background_video.avi'\n",
        "    bg = cv2.imread(background)\n",
        "    bg = cv2.resize(bg,(512,512), fx=1, fy=1)\n",
        "    \n",
        "  # video capture variables\n",
        "  output_not_created = True\n",
        "  vidcap = cv2.VideoCapture(input_video)\n",
        "  iter = 1\n",
        "\n",
        "  with torch.no_grad():\n",
        "    # reading \n",
        "    has_frames, img = vidcap.read()\n",
        "    while has_frames:\n",
        "\n",
        "        # saving orginal size\n",
        "        org_shape = (img.shape[1],img.shape[0])\n",
        "\n",
        "        # resizing image for forward propagation\n",
        "        img = cv2.resize(img,(512,512), fx=1, fy=1)\n",
        "        img_ = to_tensor(img)\n",
        "        img_ = torch.unsqueeze(img_, 0)\n",
        "        img_ = img_.cuda()\n",
        "        out = net(img_)[0]\n",
        "        parsing = out.squeeze(0).cpu().numpy().argmax(0)\n",
        "\n",
        "        if blur:\n",
        "          bg = cv2.GaussianBlur(img,kernel_size,0)\n",
        "        \n",
        "        # resizing background and creating write object for video\n",
        "        if output_not_created:\n",
        "          output_not_created = False\n",
        "          out_file = cv2.VideoWriter(output_file_name,cv2.VideoWriter_fourcc(*'DIVX'),fps,org_shape)\n",
        "          \n",
        "\n",
        "        # combining background and original image\n",
        "        bg_flag = np.expand_dims(parsing,2) == 0\n",
        "        new_img = bg*bg_flag + img*(~bg_flag)\n",
        "        new_img = cv2.resize(new_img,org_shape)\n",
        "        out_file.write(new_img)\n",
        "        \n",
        "        vidcap.set(cv2.CAP_PROP_POS_FRAMES,iter)\n",
        "        iter += 1\n",
        "        has_frames, img = vidcap.read()\n",
        "        if iter %100 == 0:\n",
        "          print(f'{iter} frames processed')\n",
        "\n",
        "  return output_file_name"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL-JezQ1Zxe8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "e6050eb4-738d-49d7-9f62-35128f50b71f"
      },
      "source": [
        "evaluate(input_video='Taking Accountability_cut.mp4',cp='79999_iter.pth',blur=False,background='thumb-1920-126995.jpg')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 frames processed\n",
            "200 frames processed\n",
            "300 frames processed\n",
            "400 frames processed\n",
            "500 frames processed\n",
            "600 frames processed\n",
            "700 frames processed\n",
            "800 frames processed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oJA5axK1e_7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "3e921bf3-f3b6-4fa5-eada-faff321722d0"
      },
      "source": [
        "evaluate(input_video='Taking Accountability_cut.mp4',cp='79999_iter.pth',blur=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 frames processed\n",
            "200 frames processed\n",
            "300 frames processed\n",
            "400 frames processed\n",
            "500 frames processed\n",
            "600 frames processed\n",
            "700 frames processed\n",
            "800 frames processed\n",
            "900 frames processed\n",
            "1000 frames processed\n",
            "1100 frames processed\n",
            "1200 frames processed\n",
            "1300 frames processed\n",
            "1400 frames processed\n",
            "1500 frames processed\n",
            "1600 frames processed\n",
            "1700 frames processed\n",
            "1800 frames processed\n",
            "1900 frames processed\n",
            "2000 frames processed\n",
            "2100 frames processed\n",
            "2200 frames processed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'blur_background_video.avi'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vgt9AyYZMu5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}